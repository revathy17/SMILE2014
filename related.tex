\section{Related Work}
\label{sec:RelatedWork}
There have been two main approaches in addressing the problem of location identification of a twitter user: \begin{inparaenum}[(1)] 
\item Using the content of the tweets: based on the premise that the online content of a user is influenced by the geographical location of the user
\item Using the network information of the user: based on the assumption that the locations of the people in a user's network and their online interaction with the user can be used to determine the user's location.
\end{inparaenum}

Content-based location detection relies on a significantly large training dataset to build a statistical model that identifies words with a local scope. Use of these words in tweets are used to narrow down the location of any user. Cheng et al. \cite{cheng2010you} proposed a probabilistic framework for estimating a Twitter user's city-level location based on the content of approximately 1000+ tweets of each user. The locality of terms was determined by its spatial variation across the United States. Their approach on a test dataset of 130689 users with 1000+ tweets each, could locate 51\% of the users within 100 miles and the average error distance was reported as 535.564 miles. The disadvantage of this approach was the assumption that a "term" is spatially significant to only one location/city. This challenge was addressed by Chang et al.~\cite{chang2012phillies} by modeling the variations as a Gausian mixture model. Their tests on the same test dataset showed an accuracy (within 100 miles) of 0.499 with 509.3 miles of average error distance.
\cite{ferrara2012web} created language models at different granularity levels from zip code to country level using a training dataset of 5.8 million geotagged tweets. At the city-level, they reported an accuracy of 65.7\% and 29.8\% on two different datasets.
 %They reported their results on two datasets - SPRITZER containing 5\% of the public twitter stream of 4 weeks and FIREHOSE containing 700,000 tweets from the Twitter Firehose. At the city-level, they reported an accuracy of 65.7\% and 29.8\% on the SPRITZER and the FIREHOSE dataset respectively.

Network based solutions requires the network information of a given user. McGee et al. ~\cite{mcgee2013location} used the interaction between users in a network to train a Decision Tree to distinguish between pairs of users likely to live close by. They reported an average error distance of 21 miles for 80\% of their users. ~\cite{rout2013s} formulated this task as a classification task and trained an SVM classifier with features based on the information of users' followers-followees who have their location information available. They tested their approach on a random sample of 1000 users and reported 50.08\% accuracy at the city level. However, the limitation of a network-based approaches is the availability of location information of people in the given user's network.   

The above mentioned approaches require prior training dataset (of either the content or network), which can be a bottleneck during disaster management. Our goal is to overcome this requirement of training data for each city by leveraging Wikipedia as the knowledge source.
%citeInferring the location of twitter messages based on user relationships.