 
\section{Approach}
\label{sec:approach}
Previous research \cite{cheng2010you} \cite{bo2012geolocation} have established that the content of a user's posts reflects his/her geographical location. We propose to use the information available in Wikipedia to establish words that are most representative of a given location. 

\subsection{Dataset}
We selected 1670 cities in the United States of America having population greater than 20000. We randomly selected 600 users containing 1000+ tweets each, from the dataset made publicly available by Cheng et al\cite{cheng2010you}.

\subsection{Creation of Background Knowledge}
Wikipedia is a crowd sourced encyclopedia. Links to internal Wikipedia pages from a given page are an important feature of all Wikipedia pages. The aim of these links is to increase the understanding of a user about the given page. For instance, the Wikipedia page of \textit{Boston, Massachusetts} \footnote{http://en.wikipedia.org/wiki/Boston} mentions the \textit{Boston Red Sox}, in the Sports section. It also provides a hyperlink to Boston Red Sox, that allows the user to navigate to the Wikipedia page of \textit{Boston Red Sox}. We base our approach on the assumption that these internal links share varying degrees of relevance to the Wikipedia page of the city. As in the previous example, the Wikipedia page of Boston also contains an internal link to \textit{Major League Baseball} which would be less representative of Boston than the \textit{Boston Red Sox}. 

The entire collection of Wikipedia is available for download\footnote{http://en.wikipedia.org/wiki/Wikipedia:Database\_download}. We use the dump dated 14-Feb-2014 to extract the internal links from the Wikipedia pages of all the cities in our dataset. Figure 1 shows the distribution of the count of internal links among all the city pages. From our dataset, \textit{Pittsburgh} had 2684 as the largest count of internal links and \textit{Round Lake Beach, Illinois} had 33 as the smallest count of internal links.

\subsection{Scoring City-Specific Entities}
Given a set of internal links for a city, we score each link to determine the degree of its relevance to the city. The more a given internal link is common to the cities in our dataset, the less it maybe relevant to one particular city. For example, in our dataset of 1650 cities, an internal link to the Wikipedia page of \textit{Barack Obama} appears 105 times as opposed to \textit{Southern California} and \textit{Golden Gate Bridge} which appear 50 and 6 times respectively. 

Mendes et al. \cite{mendes2011dbpedia} proposed \textit{Inverse Candidate Frequency} for the task of entity disambiguation in DBPedia Spotlight. The idea behind ICF is that "a word commonly co-occuring with many resources is less discriminative overall". We use this intuition to identify the discriminative ability of an internal link with respect to a city. Let C be the set of cities in our dataset. Let I be the set of internal links for a city c $\in$ C. The ICF of an internal link i $\in$ I, that appears in \textit{n} cities, is defined as:
\begin{equation}
	ICF(i) = \log |C|- \log n
\end{equation}

\subsection{Annotation of Tweets}







